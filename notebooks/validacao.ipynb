{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75211f1d",
   "metadata": {},
   "source": [
    "Esse notebook ser√° utilizado para comparar as bases finais geradas pelo ETL e pelo ELT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36620fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos fazer os imports necess√°rios\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar ao Data Warehouse criado pelo ELT\n",
    "db_path = 'samu_dw.db'\n",
    "if not os.path.exists(db_path):\n",
    "    print(\"‚ùå ERRO: Arquivo samu_dw.db n√£o encontrado. Rode o notebook ELT_SAMU.ipynb primeiro.\")\n",
    "else:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"‚úÖ Conectado ao Banco de Dados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query para descontruir o star schema refazendo a tabela plana\n",
    "query_sql = \"\"\"\n",
    "SELECT \n",
    "    f.id_atendimento,\n",
    "    f.data as data,\n",
    "    f.hora_minuto,\n",
    "    l.municipio,\n",
    "    l.bairro,\n",
    "    m.tipo,\n",
    "    m.subtipo,\n",
    "    m.motivo_desfecho_limpo as motivo_desfecho,\n",
    "    f.sexo,\n",
    "    f.idade,\n",
    "    f.ano_origem\n",
    "FROM fato_atendimentos f\n",
    "LEFT JOIN dim_local l ON f.id_local = l.id_local\n",
    "LEFT JOIN dim_motivo m ON f.id_motivo = m.id_motivo\n",
    "\"\"\"\n",
    "#carregando o banco para Pandas \n",
    "df_elt = pd.read_sql(query_sql, conn)\n",
    "\n",
    "# Ajuste de tipos para bater com o Pandas\n",
    "df_elt['idade'] = pd.to_numeric(df_elt['idade'])\n",
    "df_elt['ano_origem'] = df_elt['ano_origem'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defini√ß√£o das colunas padr√£o\n",
    "colunas_padrao = [\n",
    "    '_id', 'data', 'hora_minuto', 'municipio', 'bairro', 'endereco',\n",
    "    'origem_chamado', 'tipo', 'subtipo', 'sexo', 'idade',\n",
    "    'motivo_finalizacao', 'motivo_desfecho'\n",
    "]\n",
    "\n",
    "try:\n",
    "    # 1. Leitura dos CSVs \n",
    "    df_23 = pd.read_csv('../data/samu_2023.csv', header=None, names=colunas_padrao, low_memory=False)\n",
    "    df_24 = pd.read_csv('../data/samu_2024.csv', header=None, names=colunas_padrao, low_memory=False)\n",
    "    df_25 = pd.read_csv('../data/samu_2025.csv', header=None, names=colunas_padrao, low_memory=False)\n",
    "    \n",
    "    # Adicionar ano de origem\n",
    "    df_23['ano_origem'] = 2023\n",
    "    df_24['ano_origem'] = 2024\n",
    "    df_25['ano_origem'] = 2025\n",
    "    \n",
    "    df_etl = pd.concat([df_23, df_24, df_25])\n",
    "    \n",
    "    # --- REPLICA√á√ÉO DAS REGRAS DE NEG√ìCIO ---\n",
    "    \n",
    "    # 2. Filtrar \"lixo\" (cabe√ßalhos repetidos no meio do arquivo)\n",
    "    df_etl = df_etl[df_etl['idade'].astype(str).str.lower() != 'idade'].copy()\n",
    "    \n",
    "    # 3. Tratamento de Idade (Converter para num√©rico e preencher com mediana)\n",
    "    df_etl['idade'] = pd.to_numeric(df_etl['idade'], errors='coerce')\n",
    "    mediana = df_etl['idade'].median()\n",
    "    df_etl['idade'] = df_etl['idade'].fillna(mediana)\n",
    "    \n",
    "    # 4. Normaliza√ß√£o de Texto (UPPER) - Igual ao SQL dim_local/dim_motivo\n",
    "    cols_upper = ['municipio', 'bairro', 'tipo', 'subtipo', 'sexo']\n",
    "    for col in cols_upper:\n",
    "        df_etl[col] = df_etl[col].astype(str).str.upper()\n",
    "    \n",
    "    # 5. Regra espec√≠fica do Motivo Desfecho (limpar prefixos num√©ricos como \"1. \", \"2. \")\n",
    "    def limpar_motivo(val):\n",
    "        val = str(val).upper()\n",
    "        if len(val) > 3 and val[0].isdigit() and val[1] == '.':\n",
    "            return val[3:].strip() # Remove \"1. \" e espa√ßos\n",
    "        return val\n",
    "        \n",
    "    df_etl['motivo_desfecho'] = df_etl['motivo_desfecho'].apply(limpar_motivo)\n",
    "    \n",
    "    # 6. Tratar Nulos do Subtipo (SQL usa COALESCE para 'NAO INFORMADO')\n",
    "    df_etl['subtipo'] = df_etl['subtipo'].replace('NAN', 'NAO INFORMADO')\n",
    "\n",
    "    # Renomear coluna de ID para bater com o SQL\n",
    "    df_etl = df_etl.rename(columns={'_id': 'id_atendimento'})\n",
    "    \n",
    "    # Selecionar apenas as colunas que existem no SQL para comparar\n",
    "    colunas_finais = [\n",
    "        'id_atendimento', 'data', 'hora_minuto', 'municipio', 'bairro', \n",
    "        'tipo', 'subtipo', 'motivo_desfecho', 'sexo', 'idade', 'ano_origem'\n",
    "    ]\n",
    "    df_etl = df_etl[colunas_finais]\n",
    "\n",
    "    print(f\"‚úÖ Dados processados via Pandas (ETL): {df_etl.shape[0]} linhas.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao processar CSVs: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37143aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar ambos os DataFrames para garantir que as linhas estejam na mesma ordem\n",
    "# Ordenamos por ID e Ano para garantir unicidade\n",
    "df_elt = df_elt.sort_values(by=['id_atendimento', 'ano_origem']).reset_index(drop=True)\n",
    "df_etl = df_etl.sort_values(by=['id_atendimento', 'ano_origem']).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- RELAT√ìRIO DE VALIDA√á√ÉO ---\")\n",
    "print(f\"Total Linhas SQL (ELT):    {len(df_elt)}\")\n",
    "print(f\"Total Linhas Pandas (ETL): {len(df_etl)}\")\n",
    "\n",
    "try:\n",
    "    # check_dtype=False √© usado porque o SQLite pode retornar floats com precis√£o levemente diferente\n",
    "    # ou strings como objetos, mas o conte√∫do deve ser igual.\n",
    "    pd.testing.assert_frame_equal(df_etl, df_elt, check_dtype=False, atol=0.01)\n",
    "    \n",
    "    print(\"\\nüèÜ SUCESSO ABSOLUTO!\")\n",
    "    print(\"A base gerada pelo ELT (SQL) √© matematicamente ID√äNTICA √† base gerada via Pandas (ETL).\")\n",
    "    print(\"O Data Warehouse est√° validado e confi√°vel.\")\n",
    "    \n",
    "except AssertionError as e:\n",
    "    print(\"\\n‚ö†Ô∏è DIVERG√äNCIA ENCONTRADA!\")\n",
    "    print(\"As bases n√£o s√£o iguais. Veja o detalhe do erro abaixo:\")\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

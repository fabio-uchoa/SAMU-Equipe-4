{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34328f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c121a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_nomes = [\n",
    "    'ID', 'DATA', 'HORA_MINUTO', 'MUNICIPIO', 'BAIRRO',\n",
    "    'ENDERECO', 'ORIGEM_CHAMADO', 'TIPO', 'SUBTIPO',\n",
    "    'SEXO', 'IDADE', 'MOTIVO_FINALIZACAO', 'MOTIVO_DESFECHO'\n",
    "]\n",
    "\n",
    "\n",
    "df_2025 = pd.read_csv('../data/samu_2025.csv', header=None, names=colunas_nomes)\n",
    "\n",
    "df_2024 = pd.read_csv('../data/samu_2024.csv', header=0, names=colunas_nomes)\n",
    "df_2023 = pd.read_csv('../data/samu_2023.csv', header=0, names=colunas_nomes)\n",
    "\n",
    "df_unificado = pd.concat([df_2025, df_2024, df_2023], ignore_index=True)\n",
    "\n",
    "df_unificado['ID'] = df_unificado.index\n",
    "df_unificado.set_index('ID', inplace=True)\n",
    "\n",
    "df_unificado['DATA'] = df_unificado['DATA'].astype(str).str.split('T').str[0]\n",
    "df_unificado['DATA'] = pd.to_datetime(df_unificado['DATA'], errors='coerce').dt.date\n",
    "\n",
    "df_unificado['HORA_MINUTO'] = df_unificado['HORA_MINUTO'].astype(str).str.strip().str[:8]\n",
    "df_unificado['HORA_MINUTO'] = pd.to_datetime(df_unificado['HORA_MINUTO'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "df_unificado['IDADE'] = pd.to_numeric(df_unificado['IDADE'], errors='coerce')\n",
    "\n",
    "\n",
    "print(df_unificado[['DATA', 'HORA_MINUTO', 'IDADE']].info())\n",
    "df_unificado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f199d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tipo real na coluna DATA:\", type(df_unificado['DATA'].iloc[0]))\n",
    "\n",
    "print(\"Tipo real na coluna HORA:\", type(df_unificado['HORA_MINUTO'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76703348",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediana_idade = df_unificado['IDADE'].median()\n",
    "\n",
    "df_unificado['IDADE'].fillna(mediana_idade, inplace=True)\n",
    "df_unificado['IDADE'] = df_unificado['IDADE'].astype(int)\n",
    "\n",
    "qtd_nulos = df_unificado['IDADE'].isnull().sum()\n",
    "\n",
    "print(\"Quantidade de valores nulos na coluna IDADE após preenchimento:\", qtd_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00af74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificado['MOTIVO_FINALIZACAO'] = df_unificado['MOTIVO_FINALIZACAO'].fillna('SEM FINALIZAÇÃO')\n",
    "\n",
    "print(\"Quantidade de nulos após tratamento:\", df_unificado['MOTIVO_FINALIZACAO'].isnull().sum())\n",
    "\n",
    "df_unificado[['MOTIVO_FINALIZACAO']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificado['ENDERECO'] = df_unificado['ENDERECO'].fillna('NÃO INFORMADO')\n",
    "\n",
    "df_unificado['ORIGEM_CHAMADO'] = df_unificado['ORIGEM_CHAMADO'].fillna('NÃO INFORMADO')\n",
    "\n",
    "print(df_unificado[['ENDERECO', 'ORIGEM_CHAMADO']].isnull().sum())\n",
    "\n",
    "df_unificado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f107ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_restantes = ['SEXO', 'SUBTIPO', 'TIPO', 'MUNICIPIO', 'BAIRRO']\n",
    "\n",
    "df_unificado[colunas_restantes] = df_unificado[colunas_restantes].fillna('NÃO INFORMADO')\n",
    "\n",
    "print(\"Contagem Final de Nulos:\")\n",
    "print(df_unificado.isnull().sum())\n",
    "\n",
    "df_unificado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_texto = ['MUNICIPIO', 'BAIRRO', 'ENDERECO', 'ORIGEM_CHAMADO', 'TIPO', 'SUBTIPO', 'SEXO', 'MOTIVO_FINALIZACAO', 'MOTIVO_DESFECHO']\n",
    "\n",
    "for col in colunas_texto:\n",
    "    df_unificado[col] = df_unificado[col].astype(str).str.upper().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_texto = ['MUNICIPIO', 'BAIRRO', 'ENDERECO', 'ORIGEM_CHAMADO', 'TIPO', 'SUBTIPO', 'SEXO', 'MOTIVO_FINALIZACAO', 'MOTIVO_DESFECHO']\n",
    "\n",
    "for col in colunas_texto:\n",
    "    print(f\"\\nValores Únicos em {col}\")\n",
    "    valores = sorted(df_unificado[col].unique())\n",
    "    print(valores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_para_limpar = [\n",
    "    '93999830', 'ANI/ALI','JOSELENE', 'JUSELITA', \n",
    "    'MARCILIA', 'R MA','RAYSSA', 'R  CELIA','JAGUARIB'\n",
    "    'MONICA', 'AV NORTE', '00', 'MONIQUE', 'CARLOS', 'SANDRO',\n",
    "    'EDVALDO', 'RECIFE', 'EDIMILSO', 'MARIA', 'MANOEL R', 'TEC ENF',\n",
    "    'ANTONIO'\n",
    "]\n",
    "\n",
    "df_unificado['ORIGEM_CHAMADO'] = df_unificado['ORIGEM_CHAMADO'].replace(valores_para_limpar, 'NÃO INFORMADO')\n",
    "\n",
    "df_unificado['ORIGEM_CHAMADO'] = df_unificado['ORIGEM_CHAMADO'].replace('ESTAB PR', 'ESTABELECIMENTO PRIVADO')\n",
    "df_unificado['ORIGEM_CHAMADO'] = df_unificado['ORIGEM_CHAMADO'].replace('ESTAB PU', 'ESTABELECIMENTO PUBLICO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos_finalizacao = df_unificado['MOTIVO_FINALIZACAO'].isnull().sum()\n",
    "print(\"Quantidade de valores nulos na coluna MOTIVO_FINALIZACAO após todas as correções:\", nulos_finalizacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_checagem = ['DATA', 'HORA_MINUTO', 'MUNICIPIO', 'BAIRRO', \n",
    "    'ENDERECO', 'ORIGEM_CHAMADO', 'TIPO', 'SUBTIPO', \n",
    "    'SEXO', 'IDADE', 'MOTIVO_FINALIZACAO', 'MOTIVO_DESFECHO']\n",
    "\n",
    "\n",
    "qtd_antes = len(df_unificado)\n",
    "df_unificado.drop_duplicates(subset=colunas_checagem, keep='first', inplace=True)\n",
    "qtd_depois = len(df_unificado)\n",
    "\n",
    "print(f\"Linhas antes: {qtd_antes}\")\n",
    "print(f\"Linhas depois: {qtd_depois}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_dias = {\n",
    "    'Monday': 'SEGUNDA-FEIRA', 'Tuesday': 'TERCA-FEIRA', 'Wednesday': 'QUARTA-FEIRA',\n",
    "    'Thursday': 'QUINTA-FEIRA', 'Friday': 'SEXTA-FEIRA', 'Saturday': 'SABADO', 'Sunday': 'DOMINGO'\n",
    "}\n",
    "\n",
    "df_unificado['DATA'] = pd.to_datetime(df_unificado['DATA'])\n",
    "df_unificado['DIA_SEMANA'] = df_unificado['DATA'].dt.day_name().map(mapa_dias)\n",
    "\n",
    "\n",
    "def definir_turno(hora_minuto):\n",
    "    try:\n",
    "        hora = int(str(hora_minuto)[:2])\n",
    "        \n",
    "        if 6 <= hora < 12:\n",
    "            return 'MANHA'\n",
    "        elif 12 <= hora < 18:\n",
    "            return 'TARDE'\n",
    "        elif 18 <= hora <= 23:\n",
    "            return 'NOITE'\n",
    "        else:\n",
    "            return 'MADRUGADA'\n",
    "    except:\n",
    "        return 'NAO INFORMADO'\n",
    "\n",
    "df_unificado['TURNO'] = df_unificado['HORA_MINUTO'].apply(definir_turno)\n",
    "\n",
    "print(\"Novas colunas geradas:\")\n",
    "df_unificado[['DATA', 'DIA_SEMANA', 'HORA_MINUTO', 'TURNO']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ba839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificado['ANO_ORIGEM'] = df_unificado['DATA'].dt.year.astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6370e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificado.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1dfdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga final no data warehouse do etl no esquema dw_etl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuracao da conexao\n",
    "DB_STRING = \"postgresql://postgres:admin123@localhost:5432/postgres\"\n",
    "engine = create_engine(DB_STRING)\n",
    "\n",
    "print(\"Iniciando carga no esquema dw_etl...\")\n",
    "\n",
    "# Limpeza das tabelas do esquema dw_etl antes de carregar\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"TRUNCATE TABLE dw_etl.fato_atendimentos CASCADE;\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE dw_etl.dim_localidade CASCADE;\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE dw_etl.dim_ocorrencia CASCADE;\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE dw_etl.dim_situacao CASCADE;\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE dw_etl.dim_paciente CASCADE;\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE dw_etl.dim_tempo CASCADE;\"))\n",
    "    conn.commit()\n",
    "\n",
    "# Carga da dimensao localidade\n",
    "print(\"Carregando Dimensão Localidade...\")\n",
    "dim_local = df_unificado[['MUNICIPIO', 'BAIRRO']].drop_duplicates().sort_values(['MUNICIPIO', 'BAIRRO']).reset_index(drop=True)\n",
    "dim_local['id_local'] = dim_local.index + 1\n",
    "# Renomeia para minusculo para bater com o banco\n",
    "dim_local = dim_local.rename(columns={'MUNICIPIO': 'municipio', 'BAIRRO': 'bairro'})\n",
    "dim_local.to_sql('dim_localidade', engine, schema='dw_etl', if_exists='append', index=False)\n",
    "\n",
    "# Carga da dimensao ocorrencia\n",
    "print(\"Carregando Dimensão Ocorrência...\")\n",
    "dim_ocorrencia = df_unificado[['ORIGEM_CHAMADO', 'TIPO', 'SUBTIPO']].drop_duplicates().sort_values(['TIPO', 'SUBTIPO']).reset_index(drop=True)\n",
    "dim_ocorrencia['id_ocorrencia'] = dim_ocorrencia.index + 1\n",
    "# Renomeia para minusculo\n",
    "dim_ocorrencia = dim_ocorrencia.rename(columns={'ORIGEM_CHAMADO': 'origem_chamado', 'TIPO': 'tipo', 'SUBTIPO': 'subtipo'})\n",
    "dim_ocorrencia.to_sql('dim_ocorrencia', engine, schema='dw_etl', if_exists='append', index=False)\n",
    "\n",
    "# Carga da dimensao situacao\n",
    "print(\"Carregando Dimensão Situação...\")\n",
    "dim_situacao = df_unificado[['MOTIVO_FINALIZACAO', 'MOTIVO_DESFECHO']].drop_duplicates().reset_index(drop=True)\n",
    "dim_situacao['id_situacao'] = dim_situacao.index + 1\n",
    "# Renomeia para minusculo\n",
    "dim_situacao = dim_situacao.rename(columns={'MOTIVO_FINALIZACAO': 'motivo_finalizacao', 'MOTIVO_DESFECHO': 'motivo_desfecho'})\n",
    "dim_situacao.to_sql('dim_situacao', engine, schema='dw_etl', if_exists='append', index=False)\n",
    "\n",
    "# Carga da dimensao paciente\n",
    "print(\"Carregando Dimensão Paciente...\")\n",
    "# Cria dataframe temporario\n",
    "df_paciente_temp = df_unificado[['SEXO', 'IDADE']].copy()\n",
    "bins = [-1, 12, 18, 59, 200]\n",
    "labels = ['CRIANCA', 'ADOLESCENTE', 'ADULTO', 'IDOSO']\n",
    "df_paciente_temp['faixa_etaria'] = pd.cut(df_paciente_temp['IDADE'], bins=bins, labels=labels).astype(str)\n",
    "\n",
    "# Remove duplicatas\n",
    "dim_paciente = df_paciente_temp[['SEXO', 'faixa_etaria']].drop_duplicates().sort_values(['SEXO']).reset_index(drop=True)\n",
    "dim_paciente['id_paciente'] = dim_paciente.index + 1\n",
    "# Renomeia para minusculo (SEXO virou sexo)\n",
    "dim_paciente = dim_paciente.rename(columns={'SEXO': 'sexo'})\n",
    "dim_paciente.to_sql('dim_paciente', engine, schema='dw_etl', if_exists='append', index=False)\n",
    "\n",
    "# Carga da dimensao tempo\n",
    "print(\"Carregando Dimensão Tempo...\")\n",
    "datas_unicas = pd.DataFrame({'data_completa': df_unificado['DATA'].unique()})\n",
    "# Converte para datetime\n",
    "datas_unicas['data_completa'] = pd.to_datetime(datas_unicas['data_completa'])\n",
    "\n",
    "datas_unicas['ano'] = datas_unicas['data_completa'].dt.year\n",
    "datas_unicas['mes'] = datas_unicas['data_completa'].dt.month\n",
    "datas_unicas['dia'] = datas_unicas['data_completa'].dt.day\n",
    "mapa_dias = {0:'SEGUNDA-FEIRA', 1:'TERCA-FEIRA', 2:'QUARTA-FEIRA', 3:'QUINTA-FEIRA', 4:'SEXTA-FEIRA', 5:'SABADO', 6:'DOMINGO'}\n",
    "datas_unicas['dia_semana'] = datas_unicas['data_completa'].dt.dayofweek.map(mapa_dias)\n",
    "datas_unicas['trimestre'] = datas_unicas['data_completa'].dt.quarter\n",
    "datas_unicas['semestre'] = np.where(datas_unicas['mes'] <= 6, 1, 2)\n",
    "\n",
    "dim_tempo = datas_unicas.sort_values('data_completa').reset_index(drop=True)\n",
    "dim_tempo['id_tempo'] = dim_tempo.index + 1\n",
    "# Converte para date\n",
    "dim_tempo['data_completa'] = dim_tempo['data_completa'].dt.date\n",
    "dim_tempo.to_sql('dim_tempo', engine, schema='dw_etl', if_exists='append', index=False)\n",
    "\n",
    "# Montagem e carga da tabela fato\n",
    "print(\"Montando e Carregando Tabela Fato...\")\n",
    "df_fato = df_unificado.copy()\n",
    "\n",
    "# Recalcula faixa etaria na fato\n",
    "df_fato['faixa_etaria'] = pd.cut(df_fato['IDADE'], bins=bins, labels=labels).astype(str)\n",
    "\n",
    "# Garante datetime para o merge\n",
    "df_fato['DATA'] = pd.to_datetime(df_fato['DATA'])\n",
    "\n",
    "# Merges usando as colunas originais maiusculas do df_fato\n",
    "df_fato = df_fato.merge(dim_local, left_on=['MUNICIPIO', 'BAIRRO'], right_on=['municipio', 'bairro'], how='left')\n",
    "df_fato = df_fato.merge(dim_ocorrencia, left_on=['ORIGEM_CHAMADO', 'TIPO', 'SUBTIPO'], right_on=['origem_chamado', 'tipo', 'subtipo'], how='left')\n",
    "df_fato = df_fato.merge(dim_situacao, left_on=['MOTIVO_FINALIZACAO', 'MOTIVO_DESFECHO'], right_on=['motivo_finalizacao', 'motivo_desfecho'], how='left')\n",
    "df_fato = df_fato.merge(dim_paciente, left_on=['SEXO', 'faixa_etaria'], right_on=['sexo', 'faixa_etaria'], how='left')\n",
    "\n",
    "# Merge com tempo\n",
    "df_fato['data_join'] = df_fato['DATA'].dt.date\n",
    "df_fato = df_fato.merge(dim_tempo, left_on='data_join', right_on='data_completa', how='left')\n",
    "\n",
    "# Selecao das colunas finais\n",
    "df_fato_final = pd.DataFrame()\n",
    "df_fato_final['fk_local'] = df_fato['id_local']\n",
    "df_fato_final['fk_ocorrencia'] = df_fato['id_ocorrencia']\n",
    "df_fato_final['fk_situacao'] = df_fato['id_situacao']\n",
    "df_fato_final['fk_paciente'] = df_fato['id_paciente']\n",
    "df_fato_final['fk_tempo'] = df_fato['id_tempo']\n",
    "df_fato_final['hora_exata'] = df_fato['HORA_MINUTO']\n",
    "df_fato_final['idade_paciente'] = df_fato['IDADE']\n",
    "df_fato_final['qtd_atendimentos'] = 1\n",
    "\n",
    "# Carga em lotes\n",
    "df_fato_final.to_sql('fato_atendimentos', engine, schema='dw_etl', if_exists='append', index=False, chunksize=2000)\n",
    "\n",
    "print(\"Carga ETL concluída no esquema dw_etl!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

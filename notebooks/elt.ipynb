{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d0910e",
   "metadata": {},
   "source": [
    "# üöë Pipeline ELT: Integra√ß√£o de Dados do SAMU (2023-2025)\n",
    "\n",
    "### üìã Sobre o Projeto\n",
    "Este notebook implementa um pipeline de dados seguindo a arquitetura **ELT (Extract, Load, Transform)** para integrar e analisar dados de atendimentos do SAMU. O objetivo √© construir um **Data Warehouse** (Esquema Estrela) para responder a perguntas de neg√≥cio sobre a efici√™ncia e demanda do servi√ßo.\n",
    "\n",
    "### üõ†Ô∏è Tecnologias e Justificativas\n",
    "Para a execu√ß√£o deste projeto, selecionamos uma *stack* tecnol√≥gica enxuta e eficiente:\n",
    "\n",
    "* **Python (Pandas):**\n",
    "    * *Por que?* O Pandas oferece fun√ß√µes robustas (`read_csv`, `to_sql`) para lidar com a leitura de arquivos CSV com sujeiras (como o arquivo de 2025 que veio sem cabe√ßalho) e gerenciar a conex√£o com o banco de dados.\n",
    "\n",
    "* **SQLite3:** Utilizado como motor de **Banco de Dados (Data Warehouse Local)**.\n",
    "    * *Por que?* Por ser um banco de dados *serverless* (baseado em arquivo), ele elimina a necessidade de configurar servidores complexos, sendo ideal para prototipagem r√°pida e garantindo que todo o processamento ocorra em ambiente SQL nativo.\n",
    "\n",
    "* **SQL:** Utilizado para **Transforma√ß√£o, Limpeza e Modelagem**.\n",
    "    * *Por que?* Em uma abordagem ELT, delegar o processamento pesado para o banco de dados √© mais perform√°tico do que iterar linhas em mem√≥ria. Usamos SQL para normalizar textos (`UPPER`), tratar nulos (`COALESCE`) e realizar *Joins* complexos para criar as Tabelas Fato e Dimens√£o.\n",
    "\n",
    "* **Matplotlib & Seaborn:** Utilizados para **Analytics e Visualiza√ß√£o**.\n",
    "    * *Por que?* Bibliotecas padr√£o de mercado para gera√ß√£o de gr√°ficos est√°ticos de alta qualidade, essenciais para compor o relat√≥rio final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73af05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80da93",
   "metadata": {},
   "source": [
    "## Setup - Cria√ß√£o da Estrutura de Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814b43e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o est√©tica dos gr√°ficos\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b474a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o auxiliar para gravar os scripts SQL no disco.\n",
    "# Isso garante que a l√≥gica de transforma√ß√£o fique separada da l√≥gica de orquestra√ß√£o (Python).\n",
    "def criar_arquivo_sql(caminho, conteudo):\n",
    "    os.makedirs(os.path.dirname(caminho), exist_ok=True)\n",
    "    with open(caminho, 'w') as f:\n",
    "        f.write(conteudo)\n",
    "    print(f\"üìÅ Script SQL criado: {caminho}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c3c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ôªÔ∏è Banco antigo 'samu_dw.db' removido com sucesso.\n",
      "‚úÖ Conex√£o estabelecida.\n"
     ]
    }
   ],
   "source": [
    "# Tenta fechar a conex√£o antiga se ela existir na mem√≥ria\n",
    "try:\n",
    "    conn.close()\n",
    "except:\n",
    "    pass # Se n√£o existir conex√£o aberta, segue o jogo\n",
    "\n",
    "# Agora tenta remover o arquivo\n",
    "db_path = 'samu_dw.db'\n",
    "if os.path.exists(db_path):\n",
    "    try:\n",
    "        os.remove(db_path)\n",
    "        print(f\"‚ôªÔ∏è Banco antigo '{db_path}' removido com sucesso.\")\n",
    "    except PermissionError:\n",
    "        print(f\"‚ö†Ô∏è AVISO: N√£o foi poss√≠vel apagar '{db_path}' porque ele est√° em uso.\")\n",
    "        print(\"   -> O c√≥digo vai reutilizar o banco existente (sem recriar do zero).\")\n",
    "        print(\"   -> Dica: Para recriar do zero, Reinicie o Kernel do notebook.\")\n",
    "\n",
    "# Cria a nova conex√£o\n",
    "conn = sqlite3.connect(db_path)\n",
    "print(\"‚úÖ Conex√£o estabelecida.\")\n",
    "\n",
    "# --- 2. DEFINI√á√ÉO DE SCHEMA (Necess√°rio para o arquivo sem cabe√ßalho) ---\n",
    "colunas_padrao = [\n",
    "    '_id', 'data', 'hora_minuto', 'municipio', 'bairro', 'endereco',\n",
    "    'origem_chamado', 'tipo', 'subtipo', 'sexo', 'idade',\n",
    "    'motivo_finalizacao', 'motivo_desfecho'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673ea5a",
   "metadata": {},
   "source": [
    "DEFINI√á√ÉO DOS SCRIPTS SQL (L√ìGICA DE NEG√ìCIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a223c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staging: Seleciona colunas √∫teis e padroniza textos (UPPER) para evitar duplicatas.\n",
    "\n",
    "sql_stg = \"\"\"\n",
    "DROP TABLE IF EXISTS stg_samu;\n",
    "CREATE TABLE stg_samu AS\n",
    "SELECT\n",
    "    _id as id_atendimento,\n",
    "    ano_origem,\n",
    "    data as data_ocorrencia,\n",
    "    hora_minuto,\n",
    "    UPPER(municipio) as municipio, -- Normaliza√ß√£o: 'Recife' vira 'RECIFE'\n",
    "    UPPER(bairro) as bairro,\n",
    "    UPPER(tipo) as tipo_ocorrencia,\n",
    "    UPPER(COALESCE(subtipo, 'NAO INFORMADO')) as subtipo, -- Tratamento de Nulos\n",
    "    motivo_desfecho,\n",
    "    idade,\n",
    "    sexo\n",
    "FROM stg_samu_raw;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e3029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimens√£o Local: Cria tabela √∫nica de locais para o Esquema Estrela.\n",
    "sql_dim_local = \"\"\"\n",
    "DROP TABLE IF EXISTS dim_local;\n",
    "CREATE TABLE dim_local AS\n",
    "SELECT DISTINCT \n",
    "    municipio, \n",
    "    bairro\n",
    "FROM stg_samu\n",
    "WHERE municipio IS NOT NULL;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fa50816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimens√£o Tempo: Explode a data em atributos anal√≠ticos (Ano, M√™s, Dia).\n",
    "\n",
    "sql_dim_tempo = \"\"\"\n",
    "DROP TABLE IF EXISTS dim_tempo;\n",
    "CREATE TABLE dim_tempo AS\n",
    "SELECT DISTINCT\n",
    "    data_ocorrencia as id_tempo,\n",
    "    strftime('%Y', data_ocorrencia) as ano,\n",
    "    strftime('%m', data_ocorrencia) as mes,\n",
    "    strftime('%d', data_ocorrencia) as dia,\n",
    "    strftime('%w', data_ocorrencia) as dia_semana\n",
    "FROM stg_samu\n",
    "WHERE data_ocorrencia IS NOT NULL;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778d8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimens√£o Motivo: Limpeza pesada de strings.\n",
    "# Removemos n√∫meros (ex: \"1. SUCESSO\") para padronizar o motivo.\n",
    "\n",
    "sql_dim_motivo = \"\"\"\n",
    "DROP TABLE IF EXISTS dim_motivo;\n",
    "CREATE TABLE dim_motivo AS\n",
    "SELECT DISTINCT\n",
    "    tipo_ocorrencia as tipo,\n",
    "    subtipo,\n",
    "    CASE \n",
    "        WHEN motivo_desfecho LIKE '%1. %' THEN SUBSTR(motivo_desfecho, 4)\n",
    "        WHEN motivo_desfecho LIKE '%2. %' THEN SUBSTR(motivo_desfecho, 4)\n",
    "        WHEN motivo_desfecho LIKE '%3. %' THEN SUBSTR(motivo_desfecho, 4)\n",
    "        ELSE UPPER(motivo_desfecho)\n",
    "    END as motivo_desfecho_limpo\n",
    "FROM stg_samu;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6775d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela Fato: O cora√ß√£o do Data Warehouse.\n",
    "# Usa CTEs (Common Table Expressions) para organizar os joins.\n",
    "\n",
    "sql_fato = \"\"\"\n",
    "-- Garante limpeza pr√©via\n",
    "DROP TABLE IF EXISTS fato_atendimentos;\n",
    "\n",
    "-- Define estrutura tipada (Boa pr√°tica de Engenharia)\n",
    "CREATE TABLE fato_atendimentos (\n",
    "    id_atendimento TEXT,\n",
    "    ano_origem INTEGER,\n",
    "    id_tempo TEXT,\n",
    "    id_local INTEGER,\n",
    "    id_motivo INTEGER,\n",
    "    idade INTEGER,\n",
    "    sexo TEXT,\n",
    "    hora_minuto TEXT\n",
    ");\n",
    "\n",
    "-- Insere dados transformados\n",
    "INSERT INTO fato_atendimentos\n",
    "WITH \n",
    "source   AS ( SELECT * FROM stg_samu ),\n",
    "d_local  AS ( SELECT rowid as id_local, municipio, bairro FROM dim_local ),\n",
    "d_motivo AS ( SELECT rowid as id_motivo, tipo, subtipo, motivo_desfecho_limpo FROM dim_motivo ),\n",
    "d_tempo  AS ( SELECT id_tempo FROM dim_tempo )\n",
    "\n",
    "SELECT \n",
    "    base.id_atendimento,\n",
    "    base.ano_origem,\n",
    "    t.id_tempo,\n",
    "    l.id_local,\n",
    "    m.id_motivo,\n",
    "    base.idade,\n",
    "    base.sexo,\n",
    "    base.hora_minuto\n",
    "FROM source AS base\n",
    "-- Join por texto normalizado (garante match mesmo com diferen√ßas de caixa)\n",
    "LEFT JOIN d_local l ON base.municipio = l.municipio AND base.bairro = l.bairro\n",
    "LEFT JOIN d_motivo m \n",
    "    ON base.tipo_ocorrencia = m.tipo \n",
    "    AND base.subtipo = m.subtipo\n",
    "    AND ((base.motivo_desfecho LIKE '%1. %' AND m.motivo_desfecho_limpo = SUBSTR(base.motivo_desfecho, 4)) \n",
    "         OR (m.motivo_desfecho_limpo = UPPER(base.motivo_desfecho)))\n",
    "LEFT JOIN d_tempo t ON base.data_ocorrencia = t.id_tempo;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b48d18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Script SQL criado: ../sql/staging/stg_samu.sql\n",
      "üìÅ Script SQL criado: ../sql/marts/dim_local.sql\n",
      "üìÅ Script SQL criado: ../sql/marts/dim_tempo.sql\n",
      "üìÅ Script SQL criado: ../sql/marts/dim_motivo.sql\n",
      "üìÅ Script SQL criado: ../sql/marts/fato_atendimentos.sql\n"
     ]
    }
   ],
   "source": [
    "# Cria√ß√£o f√≠sica dos arquivos na pasta sql/\n",
    "criar_arquivo_sql('../sql/staging/stg_samu.sql', sql_stg)\n",
    "criar_arquivo_sql('../sql/marts/dim_local.sql', sql_dim_local)\n",
    "criar_arquivo_sql('../sql/marts/dim_tempo.sql', sql_dim_tempo)\n",
    "criar_arquivo_sql('../sql/marts/dim_motivo.sql', sql_dim_motivo)\n",
    "criar_arquivo_sql('../sql/marts/fato_atendimentos.sql', sql_fato)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669bf549",
   "metadata": {},
   "source": [
    "### Etapa 1: Extract & Load (EL)\n",
    "\n",
    "Nesta etapa, ingerimos os arquivos CSV. \n",
    "Foi identificado um **desafio de qualidade de dados**: o arquivo de **2025 n√£o possui cabe√ßalho**, enquanto os de 2023 e 2024 possuem.\n",
    "\n",
    "**Estrat√©gia:**\n",
    "1.  Definimos manualmente os nomes das colunas para garantir alinhamento (Schema Enforcement).\n",
    "2.  Adicionamos a coluna `ano_origem` para rastrear de qual arquivo o dado veio.\n",
    "3.  Carregamos tudo para uma tabela de *Staging* (`stg_samu_raw`) no banco, sem filtros, preservando o dado original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b64dcdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_34452\\505856528.py:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_25 = pd.read_csv('../data/samu_2025.csv', header=None, names=colunas_padrao)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sucesso! 539519 registros carregados na tabela 'stg_samu_raw'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Leitura dos CSVs (Extract)\n",
    "    # 2023 e 2024 possuem cabe√ßalho, o Pandas l√™ automaticamente\n",
    "    df_23 = pd.read_csv('../data/samu_2023.csv')\n",
    "    df_24 = pd.read_csv('../data/samu_2024.csv')\n",
    "    \n",
    "    # 2025 N√ÉO tem cabe√ßalho. Usamos 'header=None' e passamos os nomes manualmente\n",
    "    df_25 = pd.read_csv('../data/samu_2025.csv', header=None, names=colunas_padrao)\n",
    "\n",
    "    # Enriquecimento (Linhagem do dado)\n",
    "    df_23['ano_origem'] = 2023\n",
    "    df_24['ano_origem'] = 2024\n",
    "    df_25['ano_origem'] = 2025\n",
    "\n",
    "    # Consolida√ß√£o e Carga (Load)\n",
    "    # Concatenamos os 3 anos em um √∫nico DataFrame\n",
    "    df_total = pd.concat([df_23, df_24, df_25])\n",
    "    \n",
    "    # Enviamos para o SQLite. \n",
    "    # if_exists='replace': recria a tabela se ela j√° existir.\n",
    "    # index=False: n√£o queremos salvar o √≠ndice num√©rico do Pandas.\n",
    "    df_total.to_sql('stg_samu_raw', conn, if_exists='replace', index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Sucesso! {len(df_total)} registros carregados na tabela 'stg_samu_raw'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro cr√≠tico na extra√ß√£o: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779e9ea",
   "metadata": {},
   "source": [
    "### Etapa 2: Transforma√ß√£o - SQL\n",
    "\n",
    "Aqui ocorre a transforma√ß√£o. Utilizamos SQL para criar o **Esquema Estrela**.\n",
    "O objetivo √© normalizar os dados para evitar repeti√ß√£o de strings (como nomes de bairros repetidos milhares de vezes) e padronizar inconsist√™ncias.\n",
    "\n",
    "**Tabelas Criadas:**\n",
    "1.  **Dimens√µes (`dim_`):** Tabelas auxiliares que cont√™m os atributos descritivos (Onde? Quando? Por qu√™?).\n",
    "2.  **Fato (`fato_`):** Tabela central que cont√©m as m√©tricas e as chaves estrangeiras (IDs) apontando para as dimens√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf3680cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_script_sql(caminho, conn):\n",
    "    print(f\"üîÑ Executando modelo: {os.path.basename(caminho)}...\")\n",
    "    try:\n",
    "        with open(caminho, 'r') as f:\n",
    "            query = f.read()\n",
    "        \n",
    "        # 'executescript' permite rodar m√∫ltiplos comandos (DROP + CREATE + INSERT)\n",
    "        conn.executescript(query)\n",
    "        print(f\"   ‚úÖ Sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8287fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Executando modelo: stg_samu.sql...\n",
      "   ‚úÖ Sucesso.\n"
     ]
    }
   ],
   "source": [
    "# 1. Staging (Limpeza Inicial)\n",
    "executar_script_sql('../sql/staging/stg_samu.sql', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0bd2ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Executando modelo: dim_local.sql...\n",
      "   ‚úÖ Sucesso.\n",
      "üîÑ Executando modelo: dim_tempo.sql...\n",
      "   ‚úÖ Sucesso.\n",
      "üîÑ Executando modelo: dim_motivo.sql...\n",
      "   ‚úÖ Sucesso.\n"
     ]
    }
   ],
   "source": [
    "# 2. Dimens√µes (Devem ser criadas antes da Fato)\n",
    "executar_script_sql('../sql/marts/dim_local.sql', conn)\n",
    "executar_script_sql('../sql/marts/dim_tempo.sql', conn)\n",
    "executar_script_sql('../sql/marts/dim_motivo.sql', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f0cc862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Executando modelo: fato_atendimentos.sql...\n",
      "   ‚úÖ Sucesso.\n"
     ]
    }
   ],
   "source": [
    "# 3. Fato (Tabela final que une tudo)\n",
    "executar_script_sql('../sql/marts/fato_atendimentos.sql', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c78f4",
   "metadata": {},
   "source": [
    "### Etapa 3: Sanity Check (Qualidade de Dados)\n",
    "\n",
    "Ap√≥s a carga, √© crucial verificar se os dados est√£o √≠ntegros.\n",
    "Identificamos uma sujeira: **linhas de cabe√ßalho do CSV original foram importadas como dados**.\n",
    "\n",
    "Isso acontece porque, ao juntar m√∫ltiplos arquivos, se n√£o tratarmos corretamente, o cabe√ßalho do segundo arquivo vira uma linha de registro no meio da tabela.\n",
    "Abaixo, detectamos esses registros (onde o ID √© a string `_id`) e aplicamos uma limpeza via `DELETE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2693a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Verificando integridade dos dados...\n",
      "‚ö†Ô∏è ALERTA: 1 registros sujos detectados (cabe√ßalho duplicado).\n",
      "üßπ Limpeza autom√°tica realizada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# --- Sanity Check ---\n",
    "print(\"\\nüîç Verificando integridade dos dados...\")\n",
    "lixo = conn.execute(\"SELECT COUNT(*) FROM fato_atendimentos WHERE id_atendimento = '_id'\").fetchone()[0]\n",
    "\n",
    "if lixo > 0:\n",
    "    print(f\"‚ö†Ô∏è ALERTA: {lixo} registros sujos detectados (cabe√ßalho duplicado).\")\n",
    "    conn.execute(\"DELETE FROM fato_atendimentos WHERE id_atendimento = '_id'\")\n",
    "    conn.commit()\n",
    "    print(\"üßπ Limpeza autom√°tica realizada com sucesso.\")\n",
    "else:\n",
    "    print(\"‚úÖ Dados √≠ntegros. Nenhuma anomalia detectada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
